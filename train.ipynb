{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import numpy \n",
    "class ItemLoader():\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    def __call__(self, file_path) -> Any:\n",
    "        return np.loadtxt(fname=file_path,dtype=numpy.float32,delimiter=\",\")\n",
    "tran = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(size=(128,128)),\n",
    "    transforms.Normalize(mean=(0.5),std=(0.5))\n",
    "    ])\n",
    "batch_size = 64\n",
    "train_dataset = datasets.DatasetFolder(root = \"./dataset/\", transform=tran,loader=ItemLoader(),extensions=[\".csv\"])\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import NoiseNet\n",
    "model = NoiseNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, data in enumerate(train_loader, 0):\n",
    "        # 获得一个批次的数据和标签\n",
    "        inputs, target = data\n",
    "        optimizer.zero_grad()\n",
    "        # 获得模型预测结果\n",
    "        outputs = model(inputs)\n",
    "        # 交叉熵代价函数outputs(64,10),target（64）\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "        running_loss += loss.item()\n",
    "    return running_loss\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    min_loss = 2.0\n",
    "    loss_list = []\n",
    "    \n",
    "    writer = SummaryWriter()\n",
    "    for epoch in range(1000):\n",
    "        loss = train(epoch)\n",
    "        writer.add_scalar(\"epoch:loss\",loss,epoch)\n",
    "        loss_list.append(loss_list)\n",
    "        if(min_loss > loss):\n",
    "            min_loss = loss\n",
    "            torch.save({\n",
    "                \"epoch\":epoch,\n",
    "                \"loss\":loss,\n",
    "                \"optimizer\":optimizer.state_dict(),\n",
    "                \"module\":model.state_dict()\n",
    "            },\"./noise.plt\")\n",
    "        print(\"[%d]LOSS %.3f\"%(epoch,loss))\n",
    "    writer.close()\n",
    "    plt.plot(loss_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
